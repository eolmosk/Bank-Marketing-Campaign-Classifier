{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d87701b",
   "metadata": {},
   "source": [
    "---\n",
    "<img src = '../logo_dh_grupo3.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d0dd1d",
   "metadata": {},
   "source": [
    "# <h1><left><ins>Entrenamiento y Evaluación de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6103ec32",
   "metadata": {},
   "source": [
    "## Importación de librerías y bases de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f19a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41bd12c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerias relevantes\n",
    "import imblearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c9eca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las bases de datos\n",
    "\n",
    "data_0 = pd.read_csv(\"base_entrenamiento.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "157405e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30360, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de filas y columnas\n",
    "\n",
    "data_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f9743f",
   "metadata": {},
   "source": [
    "La base de datos tiene 30,360 observaciones de 21 columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1c2a72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30360 entries, 0 to 30359\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   housing               30360 non-null  int64  \n",
      " 1   loan                  30360 non-null  int64  \n",
      " 2   contact               30360 non-null  int64  \n",
      " 3   campaign              30360 non-null  int64  \n",
      " 4   emp.var.rate          30360 non-null  float64\n",
      " 5   cons.price.idx        30360 non-null  float64\n",
      " 6   cons.conf.idx         30360 non-null  float64\n",
      " 7   euribor3m             30360 non-null  float64\n",
      " 8   nr.employed           30360 non-null  float64\n",
      " 9   y                     30360 non-null  int64  \n",
      " 10  married               30360 non-null  int64  \n",
      " 11  month_cat             30360 non-null  int64  \n",
      " 12  age_cat_(34.0, 44.0]  30360 non-null  int64  \n",
      " 13  age_cat_(44.0, 69.0]  30360 non-null  int64  \n",
      " 14  job_cat_1             30360 non-null  int64  \n",
      " 15  job_cat_2             30360 non-null  int64  \n",
      " 16  education_cat_1       30360 non-null  int64  \n",
      " 17  education_cat_2       30360 non-null  int64  \n",
      " 18  day_of_week_2         30360 non-null  int64  \n",
      " 19  day_of_week_3         30360 non-null  int64  \n",
      " 20  day_of_week_4         30360 non-null  int64  \n",
      " 21  day_of_week_5         30360 non-null  int64  \n",
      "dtypes: float64(5), int64(17)\n",
      "memory usage: 5.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Nombre y tipo de columnas, ademas de cantidad de filas no nulas\n",
    "\n",
    "data_0.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32158c4",
   "metadata": {},
   "source": [
    "Hay 10 variables numéricas y 11 categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b2925ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable target (y)\n",
    "X = data_0.drop('y', axis = 1)\n",
    "\n",
    "y = data_0['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cccf2faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos el dataset en Train y Test:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.30,\n",
    "                                                   random_state = 42,\n",
    "                                                   stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "432b75c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sd = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "503b1928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizamos las variables continuas:\n",
    "variables_continuas = ['campaign', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m',\n",
    "                       'nr.employed']\n",
    "\n",
    "X_train[variables_continuas] = sd.fit_transform(X_train[variables_continuas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe650297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformamos las variables continuas en x_test con la estandarizacion aprendida en el paso anterior (con los datos de entrenamiento)\n",
    "X_test[variables_continuas] = sd.transform(X_test[variables_continuas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9711e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atendemos el problema del desbalanceo de clases con random oversampler:\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(sampling_strategy = 'minority')\n",
    "\n",
    "X_train_os, y_train_os = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de481579",
   "metadata": {},
   "source": [
    "# KNN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a1c71",
   "metadata": {},
   "source": [
    "## con GridSearch y Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "137039a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos un KNN sin modificar hiperparametros a modo de linea de base:\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00fdf7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train_os, y_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "415efb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_base_y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "328c5a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92      8612\n",
      "           1       0.20      0.52      0.28       496\n",
      "\n",
      "    accuracy                           0.86      9108\n",
      "   macro avg       0.58      0.70      0.60      9108\n",
      "weighted avg       0.93      0.86      0.89      9108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, knn_base_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "423fd4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7553 1059]\n",
      " [ 238  258]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, knn_base_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20dfbb6",
   "metadata": {},
   "source": [
    "Ahora utilizaremos Randomized search para buscar mejores hiperparametros. Si bien Randomized Search no es exahustivo, sino que toma aleatoriamente combinaciones de hiperparametros, es justamente por ello que es más veloz, y sus resultados suelen ser cercanos a los de una busqueda exahustiva. En todo caso, una vez elegido el mejor modelo, se puede correr nuevamente con un GridSearch para obtener los mejores hiperametros posibles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15372e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], 'metric': ['minkowski', 'manhattan']}\n"
     ]
    }
   ],
   "source": [
    "#Preparamos un Grid para encontrar el mejor hiperparametro para K\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Hacemos el grid con una lista de n_neighbours que va del 1 al 20 vecinos mas cercanos.\n",
    "k_range = list(range(1, 21))\n",
    "# Tambien evaluamos distintas metricas de distancia:\n",
    "metrics = [\"minkowski\", \"manhattan\"]\n",
    "param_grid = dict(n_neighbors=k_range, metric=metrics )\n",
    "#Imprimimos la grilla de parametros:\n",
    "print(param_grid)\n",
    "\n",
    "# Indicamos 10 folds para luego hacer cross validation\n",
    "folds=StratifiedKFold(n_splits=10, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0326d0",
   "metadata": {},
   "source": [
    "Decidimos que los scorings que tienen relevancia practica en este caso son Recall, Precision y, por ende, F1-score ya que este ultimo pone en relacion a los dos primeros. \n",
    "Cuando analcemos los resultados veremos en detalle por que seleccionamos estos scorings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5801a90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos distintas RandomizedSearchCV cada una con un Scoring diferente. \n",
    "\n",
    "# F1\n",
    "rgrid_f1 = RandomizedSearchCV(knn, param_grid, n_iter=15, n_jobs=-2, cv=folds, scoring='f1',random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "624bb359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall\n",
    "rgrid_recall = RandomizedSearchCV(knn, param_grid, n_iter=15, n_jobs=-2, cv=folds, scoring='recall',random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f1cce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "rgrid_precision = RandomizedSearchCV(knn, param_grid, n_iter=15, n_jobs=-2, cv=folds, scoring='precision',random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d18291f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "                   estimator=KNeighborsClassifier(), n_iter=15, n_jobs=-2,\n",
       "                   param_distributions={'metric': ['minkowski', 'manhattan'],\n",
       "                                        'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                                                        9, 10, 11, 12, 13, 14,\n",
       "                                                        15, 16, 17, 18, 19,\n",
       "                                                        20]},\n",
       "                   random_state=42, scoring='f1')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# realizamos los RandomizedSearchCV:\n",
    "\n",
    "#RScv con F1-score\n",
    "rgrid_f1.fit(X_train_os, y_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ed157c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "                   estimator=KNeighborsClassifier(), n_iter=15, n_jobs=-2,\n",
       "                   param_distributions={'metric': ['minkowski', 'manhattan'],\n",
       "                                        'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                                                        9, 10, 11, 12, 13, 14,\n",
       "                                                        15, 16, 17, 18, 19,\n",
       "                                                        20]},\n",
       "                   random_state=42, scoring='recall')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RScv cpn Recall\n",
    "rgrid_recall.fit(X_train_os, y_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90a25d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=10, random_state=42, shuffle=True),\n",
       "                   estimator=KNeighborsClassifier(), n_iter=15, n_jobs=-2,\n",
       "                   param_distributions={'metric': ['minkowski', 'manhattan'],\n",
       "                                        'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                                                        9, 10, 11, 12, 13, 14,\n",
       "                                                        15, 16, 17, 18, 19,\n",
       "                                                        20]},\n",
       "                   random_state=42, scoring='precision')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RScv con Precision\n",
    "rgrid_precision.fit(X_train_os, y_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d61b602f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parametros para f1: {'n_neighbors': 6, 'metric': 'manhattan'}\n",
      "Mejores parametros para recall: {'n_neighbors': 13, 'metric': 'minkowski'}\n",
      "Mejores parametros para precision: {'n_neighbors': 6, 'metric': 'manhattan'}\n"
     ]
    }
   ],
   "source": [
    "#Imprimimos los estimadores seleccionados en cada RScv:\n",
    "print(\"Mejores parametros para f1:\", rgrid_f1.best_params_)\n",
    "print(\"Mejores parametros para recall:\", rgrid_recall.best_params_)\n",
    "print(\"Mejores parametros para precision:\", rgrid_precision.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbc80ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor puntaje de f1-score: 0.9371149903005515\n",
      "Mejor puntaje de recall: 0.9984570923382095\n",
      "Mejor puntaje de precision: 0.8919950020856569\n"
     ]
    }
   ],
   "source": [
    "#imprimimos los mejores scores de cada RScv\n",
    "print(\"Mejor puntaje de f1-score:\", rgrid_f1.best_score_)\n",
    "print(\"Mejor puntaje de recall:\", rgrid_recall.best_score_)\n",
    "print(\"Mejor puntaje de precision:\", rgrid_precision.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f1c308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos con y a partir de X_test:\n",
    "y_pred_rgrid_f1 = rgrid_f1.predict(X_test)\n",
    "\n",
    "y_pred_rgrid_recall = rgrid_recall.predict(X_test)\n",
    "\n",
    "y_pred_rgrid_precision = rgrid_precision.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "242dfa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_rgrid_f1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92      8612\n",
      "           1       0.20      0.52      0.29       496\n",
      "\n",
      "    accuracy                           0.86      9108\n",
      "   macro avg       0.59      0.70      0.61      9108\n",
      "weighted avg       0.93      0.86      0.89      9108\n",
      "\n",
      "y_pred_rgrid_recall:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88      8612\n",
      "           1       0.16      0.69      0.26       496\n",
      "\n",
      "    accuracy                           0.79      9108\n",
      "   macro avg       0.57      0.74      0.57      9108\n",
      "weighted avg       0.93      0.79      0.84      9108\n",
      "\n",
      "y_pred_rgrid_precision:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92      8612\n",
      "           1       0.20      0.52      0.29       496\n",
      "\n",
      "    accuracy                           0.86      9108\n",
      "   macro avg       0.59      0.70      0.61      9108\n",
      "weighted avg       0.93      0.86      0.89      9108\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (f\"y_pred_rgrid_f1:\\n\",\n",
    "       classification_report(y_test, y_pred_rgrid_f1))\n",
    "print (f\"y_pred_rgrid_recall:\\n\",\n",
    "       classification_report(y_test, y_pred_rgrid_recall))\n",
    "print (f\"y_pred_rgrid_precision:\\n\",\n",
    "       classification_report(y_test, y_pred_rgrid_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c88b9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_rgrid_f1 confusion matrix: \n",
      " [[7581 1031]\n",
      " [ 237  259]]\n",
      "y_pred_rgrid_recall confusion matrix: \n",
      " [[6854 1758]\n",
      " [ 155  341]]\n",
      "y_pred_rgrid_precision confusion matrix: \n",
      " [[7581 1031]\n",
      " [ 237  259]]\n"
     ]
    }
   ],
   "source": [
    "confusion_f1 = confusion_matrix(y_test, y_pred_rgrid_f1)\n",
    "print(f\"y_pred_rgrid_f1 confusion matrix: \\n\", confusion_f1)\n",
    "confusion_recall = confusion_matrix(y_test, y_pred_rgrid_recall)\n",
    "print(f\"y_pred_rgrid_recall confusion matrix: \\n\",confusion_recall)\n",
    "confusion_precision = confusion_matrix(y_test, y_pred_rgrid_precision)\n",
    "print(f\"y_pred_rgrid_precision confusion matrix: \\n\",confusion_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b2776",
   "metadata": {},
   "source": [
    "Vemos que precision y F1 nos dan la mejor relacion entre la cantidad de llamados y la cantidad de casos de exito, mientras que recall toma la mayor cantidad de casos exitosos aunque a costa de un mayor esfuerzo (costo) en terminos de llamados.\n",
    "\n",
    "Para ser claros con las metricas de evaluacion, podemos decir que la precisión es la capacidad del clasificador de no etiquetar como positiva una muestra negativa (es decir NO etiquetar como \"clientes que van a realizar un deposito a plazo fijo\" a aquellos clientes que no tienen intenciones de hacerlo), y la recall es la capacidad del clasificador de encontrar a todos los cliente que SI harian un deposito a plazo fijo dentro del universo de clientes a clasificar. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f2db44",
   "metadata": {},
   "source": [
    "Toadavia hay espacios de mejora de lo obtenido a partir del modelo, por ejemplo estableciendo un umbrar (threshold) relacionado con la probabilidad de que una observacion perteneszca a una clase o a otra. Todas las observaciones son analizadas y el modelo establece para cada observacion una probablidad (un valor entre 0 y 1) de que esa observacion sea caso de exito (en este caso seria que el cliente haga un deposito a plazo fijo). \n",
    "\n",
    "Por default el modelo cailifica como 0 a todos aquellos clientes cuya probabilidad de exito sea menor a 0.5 y como 1(exito) a todos aquellos clientes cuya probabilidad de exito sea mayor a 0.5. Esto puede ser redefinido a voluntad y encontrar estrategias que busquen encontrar el mejor equilibrio entre una serie de errores posibles, a saber: \n",
    "\n",
    "- Se puede establecer un parametro mas duro (ej: probabilidad minima de 0.8 de probabilidad para ser considerado 1)\n",
    "En este caso es mas \"dificil\" que un cliente sea catalogado como 1, por lo que solo aquellos clientes que \"muy probablemente\" adquieran el credito seran seleccionados. Esto establece una mejor relacion entre la cantidad de llamados a realizarse y la cantidad de casos de exito. Sin embargo, justamente porque es tan dificil que un cliente sea catalogaso como 1, no son clasificados como potenciales depositantes algunos clientes que si hubieran hecho el deposito a plazo fijo. Es decir, que se pierden algunos plazos fijos, pero se prodice un ahorro en el costo y duracion de la campaña, sin mencionar que no se importuna a clientes que no tienen la intencion, o la posibilidad de hacer depositos a plazo fijo. \n",
    "\n",
    "- O se puede establecer un parametro mas laxo (ej: probabilidad minima de 0.3 para ser considerado 1)\n",
    "Esta seria la situacion inversa, se prioriza captar a todos los posibles clientes que harian un deposito plazo fijo a costa de clasificar como exitosos a una gran cantidad de clientes que no van a realizar un plazo fijo, esto aunmenta el costo de la campaña y probablemente su duracion, pero tiene la ventaja de que el resultado final sera de mas plazos fijos. \n",
    "\n",
    "Elegir como regular este umbral dependera de encontrar la mejor relacion entre los costos asosciados a la campaña y de los beneficios para el banco obtenidos con cada nuevo plazo fijo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5177f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# realizasmos un predict_proba para obtener las probabilidades de exito de cada cliente\n",
    "y_pred_proba_f1 = rgrid_f1.predict_proba(X_test)\n",
    "\n",
    "y_pred_proba_recall = rgrid_recall.predict_proba(X_test)\n",
    "\n",
    "y_pred_proba_precision = rgrid_precision.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "75a7572b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_proba_f1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92      8612\n",
      "           1       0.20      0.52      0.29       496\n",
      "\n",
      "    accuracy                           0.86      9108\n",
      "   macro avg       0.59      0.70      0.61      9108\n",
      "weighted avg       0.93      0.86      0.89      9108\n",
      "\n",
      "y_proba_f1 confusion matrix: \n",
      " [[7581 1031]\n",
      " [ 237  259]]\n"
     ]
    }
   ],
   "source": [
    "#Binarizamos a unos y ceros estableciendo el umbral en funcion del criterio elegido. \n",
    "from sklearn.preprocessing import binarize\n",
    "y_proba_f1 = binarize(y_pred_proba_f1, threshold=0.5)[:,1]\n",
    "\n",
    "print (f\"y_proba_f1:\\n\",\n",
    "       classification_report(y_test, y_proba_f1))\n",
    "confusion_f1_proba = confusion_matrix(y_test, y_proba_f1)\n",
    "print(f\"y_proba_f1 confusion matrix: \\n\",confusion_f1_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2452f535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_proba_recall:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92      8612\n",
      "           1       0.20      0.57      0.30       496\n",
      "\n",
      "    accuracy                           0.85      9108\n",
      "   macro avg       0.59      0.72      0.61      9108\n",
      "weighted avg       0.93      0.85      0.89      9108\n",
      "\n",
      "y_proba_recall confusion matrix: \n",
      " [[7503 1109]\n",
      " [ 215  281]]\n"
     ]
    }
   ],
   "source": [
    "#Probamos lo mismo con Recall:\n",
    "y_proba_recall = binarize(y_pred_proba_recall, threshold=0.7)[:,1]\n",
    "\n",
    "print (f\"y_proba_recall:\\n\",\n",
    "       classification_report(y_test, y_proba_recall))\n",
    "confusion_recall_proba = confusion_matrix(y_test, y_proba_recall)\n",
    "print(f\"y_proba_recall confusion matrix: \\n\",confusion_recall_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4976f567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_proba_precision:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91      8612\n",
      "           1       0.19      0.62      0.29       496\n",
      "\n",
      "    accuracy                           0.84      9108\n",
      "   macro avg       0.58      0.74      0.60      9108\n",
      "weighted avg       0.93      0.84      0.88      9108\n",
      "\n",
      "y_proba_precision confusion matrix: \n",
      " [[7332 1280]\n",
      " [ 189  307]]\n"
     ]
    }
   ],
   "source": [
    "# Y con Precision:\n",
    "y_proba_precision = binarize(y_pred_proba_precision, threshold=0.4)[:,1]\n",
    "\n",
    "print (f\"y_proba_precision:\\n\",\n",
    "       classification_report(y_test, y_proba_precision))\n",
    "\n",
    "confusion_precision_proba = confusion_matrix(y_test, y_proba_precision)\n",
    "print(f\"y_proba_precision confusion matrix: \\n\",confusion_precision_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b684ede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_llamados_test = len(y_test)\n",
    "porcentaje_test = (len(y_test)*100)/len(y_test)\n",
    "exitos_en_test = y_test.sum()\n",
    "llam_x_exito_test = (len(y_test)/(y_test.sum())).round(1)\n",
    "porcentaje_del_total_en_test= ((y_test.sum()*100)/y_test.sum())\n",
    "\n",
    "total_llamados_knn_f1 = (confusion_f1_proba[0,1]+confusion_f1_proba[1,1])\n",
    "porcentaje_knn_f1 = (total_llamados_knn_f1*100)/len(y_test)\n",
    "exitos_knn_f1= confusion_f1_proba[1,1]\n",
    "llam_x_exito_en_knn_f1 = ((confusion_f1_proba[0,1]+confusion_f1_proba[1,1])/confusion_f1_proba[1,1]).round(1)\n",
    "porcentaje_del_total_en_knn_f1=  ((confusion_f1_proba[1,1]*100)/y_test.sum()).round(1)\n",
    "\n",
    "total_llamados_knn_recall = (confusion_recall_proba[0,1]+confusion_recall_proba[1,1])\n",
    "porcentaje_knn_recall = (total_llamados_knn_recall*100)/len(y_test)\n",
    "exitos_knn_recall = confusion_recall_proba[1,1]\n",
    "llam_x_exito_en_knn_recall  = ((confusion_recall_proba[0,1]+confusion_recall_proba[1,1])/confusion_recall_proba[1,1]).round(1)\n",
    "porcentaje_del_total_en_knn_recall = ((confusion_recall_proba[1,1]*100)/y_test.sum()).round(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6a8c0cb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'recall_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-80a9cc1044bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_proba_recall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'recall_score'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "9654e87b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "469d82dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelo</th>\n",
       "      <th>total_llamados</th>\n",
       "      <th>%_del_total_de_llamados</th>\n",
       "      <th>exitos</th>\n",
       "      <th>llamados_x_cada_exito</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y_test-fuerza_bruta-</td>\n",
       "      <td>9108</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>496</td>\n",
       "      <td>18.4</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn_recall</td>\n",
       "      <td>1390</td>\n",
       "      <td>15.261309</td>\n",
       "      <td>281</td>\n",
       "      <td>4.9</td>\n",
       "      <td>56.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knn_f1</td>\n",
       "      <td>1290</td>\n",
       "      <td>14.163373</td>\n",
       "      <td>259</td>\n",
       "      <td>5.0</td>\n",
       "      <td>52.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 modelo  total_llamados  %_del_total_de_llamados  exitos  \\\n",
       "0  y_test-fuerza_bruta-            9108               100.000000     496   \n",
       "1            knn_recall            1390                15.261309     281   \n",
       "2                knn_f1            1290                14.163373     259   \n",
       "\n",
       "   llamados_x_cada_exito  recall  \n",
       "0                   18.4   100.0  \n",
       "1                    4.9    56.7  \n",
       "2                    5.0    52.2  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = pd.DataFrame()\n",
    "est[\"modelo\"]= [\"y_test-fuerza_bruta-\",\"knn_recall\",\"knn_f1\"]\n",
    "est[\"total_llamados\"] = [total_llamados_test, total_llamados_knn_recall, total_llamados_knn_f1]\n",
    "est[\"%_del_total_de_llamados\"] = [porcentaje_test, porcentaje_knn_recall, porcentaje_knn_f1]\n",
    "est[\"exitos\"] = [exitos_en_test, exitos_knn_recall, exitos_knn_f1]\n",
    "est[\"llamados_x_cada_exito\"] = [llam_x_exito_test, llam_x_exito_en_knn_recall, llam_x_exito_en_knn_f1]\n",
    "est[\"recall\"] = [porcentaje_del_total_en_test, porcentaje_del_total_en_knn_recall, porcentaje_del_total_en_knn_f1]\n",
    "est.sort_values(\"recall\", ascending=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deab2bdf",
   "metadata": {},
   "source": [
    "Podemos decir que el mejor modelo de KNN es KNN_RECALL que captura el 56.7 de los casos de exitos con un costo que es proporcional al 15,3% del costo de la campaña anterior (con metodo de fuerza bruta, es decir, llamar a todos los clientes). \n",
    "\n",
    "Se puede reducir significativamente el esfuerzo de campaña y aun asi obtener resultados. Esto se traduce en que se pueden hacer campañas mas cortas pre seleccionando solo aquellos clientes del banco que tengan altas probabilidades de exito. Disminuyendo la duracion y el costo de la campaña.\n",
    "\n",
    "Hemos encontrado en estos hiperparametros cierto equilibrio entre efectividad y eficacia. Podriamos elegir otros hiperparametoros que resultarian en un modelo que identificaria mejor a los casos de exito (es decir no dejar afuera ningun cliente que hubiera aceptado hacer un deposito a plazo fijo), pero aumentarian los llamados disminuyendo la efecacia del sistema. \n",
    "\n",
    "Hasta que punto conviene cambiar llamados por plazos fijos es un criterio que debiera definir el banco en funcion de costos y beneficios. Es decir si prefiere invertir en mas llamados para captar la mayor catidad de plazos fijos posibles, o buscar algun equilibrio entre minimizar la inversion en la campaña y aumentar su eficiencia. \n",
    "\n",
    "De todos modos todavia quedan modelos mas complejos para ser evaluados como XGBoost, RandomForest, etc. que podrían arrojar mejores resultados..\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6d62c00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dump sucess! =)\n"
     ]
    }
   ],
   "source": [
    "#Guardamos los modelos entrenados en archivos picke para su posterior acceso:\n",
    "\n",
    "import pickle\n",
    "with open('knn-recall','wb') as f:\n",
    "    pickle.dump(rgrid_recall,f)\n",
    "    print('dump sucess! =)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c3fe38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
